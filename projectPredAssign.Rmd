---
title: "Prediction Assignment for Practical Machine Learning"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import necessary libarires 
```{r include=TRUE}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
```

# Get Data
## Download and save data for training and testing if it does not already exist.
```{r include=TRUE}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile, method="curl")
}
```

## Take the downloaded data and convert it into data into data frames.
```{r include=TRUE}
trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
dim(trainRaw)

```


```{r include=TRUE}
dim(testRaw)
```


# Clean the data
## Clean the data and get rid of observations with empty/missing values as well  meaningless data.

```{r include=TRUE}
sum(complete.cases(trainRaw))
```

## Remove columns that contain NA values.

```{r}
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0] 
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0] 

```
## Get rid of columns that do not have good accelerometer measurements.
```{r}
classe <- trainRaw$classe
trainRemove <- grepl("^X|timestamp|window", names(trainRaw))
trainRaw <- trainRaw[, !trainRemove]
trainCleaned <- trainRaw[, sapply(trainRaw, is.numeric)]
trainCleaned$classe <- classe
testRemove <- grepl("^X|timestamp|window", names(testRaw))
testRaw <- testRaw[, !testRemove]
testCleaned <- testRaw[, sapply(testRaw, is.numeric)]
```

## The cleaned training set contains 19622 observations with 53 covariants. Testing set contains 20 observations and 53 variables. The required variable "classe" is still in the cleaned training set.




# Perform data slicing

## Split the cleaned training set into a training set (70%) and a validation data set (30%). Validation data set used to conduct cross validation in later steps.

```{r}
set.seed(22519) # random see that is resued for reproducibile purpose
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
```

# Data Modeling
## We fit a predictive model for activity recognition using Random Forest algorithm because it automatically selects important variables. It is also good when comparing correlated covariates and outliers in general. A 5-fold cross validation is when applying the algorithm.
```{r}
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf

```
## Estimate the performance of the model on the validation data set.
```{r}
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)

accuracy <- postResample(predictRf, testData$classe)
accuracy
```


```{r}
myoose <- 1 - as.numeric(confusionMatrix(testData$classe, predictRf)$overall[1])
myoose
```


## The estimated accuracy of the model is very high! Its approximatley 99.% and the estimated out-of-sample error is 0.58%.

# Predicting for Test Data Set

## Model is applied to the original testing set. 
## The problem_id column is removed from the data set.
```{r}
result <- predict(modelRf, testCleaned[, -length(names(testCleaned))])
result

```

# Visulizations of the Data

## Plot: Correlation Matrix 

```{r}
corrPlot <- cor(trainData[, -length(names(trainData))])
corrplot(corrPlot, method="color")
```




